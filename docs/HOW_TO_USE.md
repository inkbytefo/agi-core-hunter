# AGI Ã‡ekirdek AvcÄ±sÄ± - KullanÄ±m KÄ±lavuzu

**SÃ¼rÃ¼m:** 1.0  
**Tarih:** 26 AÄŸustos 2025  
**Hedef Kitle:** AraÅŸtÄ±rmacÄ±lar, ML MÃ¼hendisleri, AGI MeraklÄ±larÄ±

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Sistem Gereksinimleri
- **Python:** 3.9+
- **RAM:** 8GB+ (16GB Ã¶nerilen)
- **GPU:** Opsiyonel (CUDA destekli)
- **Disk:** 5GB boÅŸ alan

### Kurulum
```bash
# 1. Projeyi klonla
git clone https://github.com/[username]/agi_core_hunter.git
cd agi_core_hunter

# 2. Sanal ortam oluÅŸtur (Ã¶nerilen)
python -m venv agi_env
source agi_env/bin/activate  # Linux/Mac
# veya
agi_env\Scripts\activate     # Windows

# 3. BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# 4. Kurulumu test et
python test_setup.py
```

### Ä°lk Demo
```bash
# Basit demo Ã§alÄ±ÅŸtÄ±r
python experiments/01_mdl_vs_ood/demo.py
```

---

## ğŸ§ª Deney Ã‡alÄ±ÅŸtÄ±rma

### Mevcut Deneyi Ã‡alÄ±ÅŸtÄ±rma

#### 1. MDL vs OOD Deneyi
```bash
cd experiments/01_mdl_vs_ood

# Tam eÄŸitim (5000 episode, ~30 dakika)
python train.py

# HÄ±zlÄ± test (100 episode, ~2 dakika)
python train.py --episodes 100 --eval-freq 25
```

#### 2. SonuÃ§larÄ± Analiz Etme
```bash
# Jupyter notebook ile analiz
jupyter notebook eval.ipynb

# Veya otomatik rapor
python -c "
import json
with open('results.json') as f:
    results = json.load(f)
print('Deney tamamlandÄ±!')
for agent, data in results.items():
    print(f'{agent}: {data[\"standard_success_rate\"]:.3f}')
"
```

### Wandb Entegrasyonu

#### Wandb Kurulumu
```bash
# Wandb hesabÄ± oluÅŸtur: https://wandb.ai
wandb login

# Veya offline mod
export WANDB_MODE=offline
```

#### CanlÄ± Takip
- **Dashboard:** https://wandb.ai/[username]/agi_core_hunter
- **Metrikler:** total_reward, success_rate, reconstruction_loss, kl_loss
- **KarÅŸÄ±laÅŸtÄ±rma:** FarklÄ± Î² deÄŸerleri arasÄ±nda

---

## ğŸ”§ Yeni Deney OluÅŸturma

### 1. Deney KlasÃ¶rÃ¼ YapÄ±sÄ±
```bash
mkdir experiments/[deney_adi]
cd experiments/[deney_adi]

# Gerekli dosyalar
touch manifest.json    # Deney konfigÃ¼rasyonu
touch train.py         # EÄŸitim scripti
touch eval.ipynb       # Analiz notebook'u
touch README.md        # Deney aÃ§Ä±klamasÄ±
```

### 2. Manifest DosyasÄ± Ã–rneÄŸi
```json
{
  "experiment": {
    "name": "Yeni Deney AdÄ±",
    "version": "1.0",
    "description": "Deney aÃ§Ä±klamasÄ±",
    "hypothesis": "Test edilecek hipotez"
  },
  "environment": {
    "type": "GridWorld",
    "config": {
      "height": 8,
      "width": 8,
      "obstacle_prob": 0.2
    }
  },
  "agents": [
    {
      "name": "TestAgent",
      "type": "MDLAgent",
      "config": {
        "latent_dim": 8,
        "beta": 1.0,
        "learning_rate": 3e-4
      }
    }
  ],
  "training": {
    "total_episodes": 1000,
    "eval_frequency": 100
  }
}
```

### 3. EÄŸitim Scripti Åablonu
```python
#!/usr/bin/env python3
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent / "src"))

from experiments.base_experiment import ExperimentRunner

def main():
    runner = ExperimentRunner("manifest.json")
    results = runner.run_experiment()
    return results

if __name__ == "__main__":
    main()
```

---

## ğŸ¤– Yeni Agent OluÅŸturma

### 1. Agent SÄ±nÄ±fÄ± Åablonu
```python
# src/agents/my_agent.py
from core.base_agent import BaseAgent
import jax.numpy as jnp

class MyAgent(BaseAgent):
    def __init__(self, config):
        super().__init__(config)
        # Agent-specific initialization
    
    def setup(self, rng_key, dummy_obs):
        # Initialize networks and optimizers
        pass
    
    def act(self, observation, rng_key):
        # Select action given observation
        action = jnp.array(0)  # Placeholder
        info = {"value": 0.0}
        return action, info
    
    def update(self, batch):
        # Update agent parameters
        metrics = {"loss": 0.0}
        return metrics
    
    def get_metrics(self):
        return {"training_step": 0}
```

### 2. Agent'Ä± Kaydetme
```python
# src/agents/__init__.py
from .mdl_agent import MDLAgent
from .my_agent import MyAgent

__all__ = ['MDLAgent', 'MyAgent']
```

### 3. Teori KartÄ± OluÅŸturma
```markdown
# docs/theory_cards/MY_PRINCIPLE.md

## ğŸ¯ Temel Ä°ddia
"ZekÃ¢ [ilke aÃ§Ä±klamasÄ±]"

## ğŸ“ Matematiksel FormÃ¼lasyon
[FormÃ¼ller ve denklemler]

## ğŸ”¬ Test Edilebilir Ã–ngÃ¶rÃ¼ler
1. [Ã–ngÃ¶rÃ¼ 1]
2. [Ã–ngÃ¶rÃ¼ 2]

## ğŸ§ª Minimal Test OrtamÄ±
[Test senaryosu aÃ§Ä±klamasÄ±]

## ğŸ“Š BaÅŸarÄ± Metrikleri
[Ã–lÃ§Ã¼m kriterleri]
```

---

## ğŸŒ Yeni Ortam OluÅŸturma

### 1. Ortam SÄ±nÄ±fÄ± Åablonu
```python
# src/envs/my_environment.py
import jax.numpy as jnp
from typing import Tuple, Dict, Any

class MyEnvironment:
    def __init__(self, config):
        self.config = config
        self.action_dim = 4
        self.obs_dim = 10
    
    def reset(self, rng_key):
        # Initialize environment state
        state = None  # Your state representation
        observation = jnp.zeros(self.obs_dim)
        return state, observation
    
    def step(self, state, action):
        # Execute one step
        new_state = state
        observation = jnp.zeros(self.obs_dim)
        reward = 0.0
        done = False
        info = {}
        return new_state, observation, reward, done, info
```

### 2. OOD Test SenaryolarÄ±
```python
def generate_ood_config(self, rng_key, ood_type):
    """Generate out-of-distribution configuration"""
    if ood_type == "parameter_shift":
        return {"param": self.param * 1.5}
    elif ood_type == "structure_change":
        return {"structure": "modified"}
    else:
        raise ValueError(f"Unknown OOD type: {ood_type}")
```

---

## ğŸ“Š SonuÃ§ Analizi

### Temel Metrikler
```python
from src.utils.metrics import (
    calculate_ood_performance_ratio,
    calculate_sample_efficiency,
    MetricsTracker
)

# Metrik hesaplama
ood_ratio = calculate_ood_performance_ratio(
    standard_performance=0.8,
    ood_performance=0.6
)

# Metrik takibi
tracker = MetricsTracker()
tracker.update(reward=10.0, success=True)
summary = tracker.get_summary()
```

### GÃ¶rselleÅŸtirme
```python
import matplotlib.pyplot as plt
import seaborn as sns

# Learning curve
plt.plot(episodes, rewards)
plt.xlabel('Episode')
plt.ylabel('Reward')
plt.title('Learning Curve')

# OOD comparison
sns.barplot(data=df, x='Agent', y='OOD_Ratio')
plt.title('OOD Performance Comparison')
```

---

## ğŸ” Debugging ve Troubleshooting

### YaygÄ±n Sorunlar

#### 1. Import HatalarÄ±
```bash
# Ã‡Ã¶zÃ¼m: PYTHONPATH ayarla
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"

# Veya sys.path kullan
import sys
sys.path.append('src')
```

#### 2. JAX/GPU SorunlarÄ±
```python
# GPU kontrolÃ¼
import jax
print(f"JAX devices: {jax.devices()}")

# CPU'ya zorla
import os
os.environ['CUDA_VISIBLE_DEVICES'] = ''
```

#### 3. Wandb BaÄŸlantÄ± SorunlarÄ±
```bash
# Offline mode
export WANDB_MODE=offline

# Yeniden login
wandb login --relogin
```

### Debug ModlarÄ±
```bash
# Verbose logging
python train.py --verbose

# Debug mode (kÃ¼Ã§Ã¼k dataset)
python train.py --debug --episodes 10

# Profiling
python -m cProfile train.py
```

---

## ğŸ§ª Test ve Validasyon

### Unit Testler
```bash
# TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r
python -m pytest tests/

# Specific test
python -m pytest tests/test_agents.py

# Coverage raporu
python -m pytest --cov=src tests/
```

### Integration Testler
```bash
# Tam pipeline testi
python test_setup.py

# Deney end-to-end testi
python experiments/01_mdl_vs_ood/demo.py
```

### Performance Testler
```bash
# Benchmark Ã§alÄ±ÅŸtÄ±r
python benchmarks/speed_test.py

# Memory profiling
python -m memory_profiler train.py
```

---

## ğŸ“š Ä°leri DÃ¼zey KullanÄ±m

### Batch Deney Ã‡alÄ±ÅŸtÄ±rma
```bash
# Ã‡oklu deney paralel Ã§alÄ±ÅŸtÄ±rma
python scripts/batch_experiments.py \
  --experiments "01_mdl_vs_ood,02_latent_dims" \
  --parallel 2
```

### Hyperparameter Sweep
```python
# Wandb sweep konfigÃ¼rasyonu
sweep_config = {
    'method': 'grid',
    'parameters': {
        'beta': {'values': [0.1, 1.0, 5.0]},
        'latent_dim': {'values': [4, 8, 16]}
    }
}

# Sweep baÅŸlat
wandb.sweep(sweep_config, project="agi_core_hunter")
```

### Distributed Training
```python
# JAX pmap kullanÄ±mÄ±
from jax import pmap
import jax.numpy as jnp

# Multi-GPU eÄŸitim
@pmap
def train_step(state, batch):
    # Training logic
    return new_state, metrics
```

---

## ğŸ¤ KatkÄ±da Bulunma

### Yeni Ä°lke Ã–nerme
1. **Issue aÃ§:** "New Principle: [Ä°lke AdÄ±]"
2. **Teori kartÄ± yaz:** `docs/theory_cards/[ILKE].md`
3. **Agent implementasyonu:** `src/agents/[ilke]_agent.py`
4. **Test deneyi:** `experiments/[xx]_[ilke]_test/`
5. **Pull request gÃ¶nder**

### Kod KatkÄ±sÄ±
```bash
# Fork ve clone
git clone https://github.com/[username]/agi_core_hunter.git
cd agi_core_hunter

# Feature branch
git checkout -b feature/new-principle

# DeÄŸiÅŸiklikleri yap
# ...

# Test et
python test_setup.py
python -m pytest

# Commit ve push
git add .
git commit -m "Add new principle: [Ä°lke AdÄ±]"
git push origin feature/new-principle

# Pull request oluÅŸtur
```

### DokÃ¼mantasyon KatkÄ±sÄ±
- Typo dÃ¼zeltmeleri
- Ã–rnek ekleme
- Tutorial yazma
- Ã‡eviri (Ä°ngilizce)

---

## ğŸ“ Destek ve Ä°letiÅŸim

### DokÃ¼mantasyon
- **Proje TanÄ±tÄ±mÄ±:** `docs/PROJE_TANITIM.md`
- **Teknik Mimari:** `docs/PROJE_TEKNIKMIMARI.md`
- **Yol HaritasÄ±:** `ROADMAP.md`
- **Teori KartlarÄ±:** `docs/theory_cards/`

### Ä°letiÅŸim KanallarÄ±
- **GitHub Issues:** Bug report ve feature request
- **GitHub Discussions:** Genel sorular ve tartÄ±ÅŸma
- **Email:** [proje-email@example.com]
- **Twitter:** [@agi_core_hunter]

### Topluluk
- **Discord:** [Davet linki]
- **Reddit:** r/agi_core_hunter
- **LinkedIn:** AGI Core Hunter grubu

---

## ğŸ“„ Lisans ve AtÄ±f

### Lisans
Bu proje MIT lisansÄ± altÄ±nda yayÄ±nlanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

### AtÄ±f
```bibtex
@software{agi_core_hunter,
  title={AGI Core Hunter: Systematic Search for AGI Principles},
  author={[Yazarlar]},
  year={2025},
  url={https://github.com/[username]/agi_core_hunter}
}
```

### TeÅŸekkÃ¼rler
- JAX/Flax ekibi
- Weights & Biases
- AÃ§Ä±k kaynak topluluÄŸu

---

**Son GÃ¼ncelleme:** 26 AÄŸustos 2025  
**Versiyon:** 1.0  
**Sonraki GÃ¼ncelleme:** Faz 2 tamamlandÄ±ÄŸÄ±nda